{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BeitForImageClassification were not initialized from the model checkpoint at microsoft/beit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 69.4819, Train Accuracy: 69.00%, Val Accuracy: 86.43%\n",
      "Epoch [2/5], Loss: 22.0745, Train Accuracy: 92.07%, Val Accuracy: 94.75%\n",
      "Epoch [3/5], Loss: 6.1060, Train Accuracy: 98.33%, Val Accuracy: 95.40%\n",
      "Epoch [4/5], Loss: 2.0920, Train Accuracy: 99.49%, Val Accuracy: 96.28%\n",
      "Epoch [5/5], Loss: 1.3074, Train Accuracy: 99.42%, Val Accuracy: 96.72%\n",
      "Model saved to beit_custom_model\n",
      "Model loaded from beit_custom_model\n",
      "Test Accuracy: 96.85%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from transformers import BeitForImageClassification\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "\n",
    "# Define directories\n",
    "DATASET_DIR = './dataset_split/'\n",
    "TRAIN_DIR = os.path.join(DATASET_DIR, 'train')\n",
    "VAL_DIR = os.path.join(DATASET_DIR, 'val')\n",
    "TEST_DIR = os.path.join(DATASET_DIR, 'test')\n",
    "\n",
    "# Define categories (classes)\n",
    "CATEGORIES = ['hurricane', 'earthquake', 'wildfire', 'not meaningful']\n",
    "\n",
    "# Device configuration (use GPU if available)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224 as expected by BEiT\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Normalize RGB values\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(VAL_DIR, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(TEST_DIR, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Load BEiT model with 4 output labels (for 4 classes) and ignore size mismatches\n",
    "model = BeitForImageClassification.from_pretrained(\n",
    "    'microsoft/beit-base-patch16-224', \n",
    "    num_labels=4,  # Adjust for 4 classes\n",
    "    ignore_mismatched_sizes=True  # Ignore mismatches in classifier layer sizes\n",
    ")\n",
    "model.to(device)  # Move model to GPU if available\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Function to save the model\n",
    "def save_model(model, path):\n",
    "    model.save_pretrained(path)  # Save the model\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(path):\n",
    "    model = BeitForImageClassification.from_pretrained(\n",
    "        path, \n",
    "        num_labels=4,  # Ensure the number of classes matches\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "    model.to(device)\n",
    "    print(f\"Model loaded from {path}\")\n",
    "    return model\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "        \n",
    "        train_accuracy = 100 * correct_predictions / total_predictions\n",
    "        val_accuracy = validate_model(model, val_loader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss:.4f}, '\n",
    "              f'Train Accuracy: {train_accuracy:.2f}%, Val Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "    # Save the model after training\n",
    "    save_model(model, 'beit_custom_model')\n",
    "\n",
    "# Function to validate the model\n",
    "def validate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images).logits\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "    \n",
    "    return 100 * correct_predictions / total_predictions\n",
    "\n",
    "# Function to test the model\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images).logits\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "    \n",
    "    test_accuracy = 100 * correct_predictions / total_predictions\n",
    "    print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    num_epochs = 5\n",
    "    # Train the model\n",
    "    train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)\n",
    "    \n",
    "    # Load the saved model (for testing or further use)\n",
    "    loaded_model = load_model('beit_custom_model')\n",
    "\n",
    "    # Test the model\n",
    "    test_model(loaded_model, test_loader)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
